{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIO data as per CoNNL should be in text format. Here we convert our csv file to `txt` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def convert_to_bio_format(df):\n",
    "    data = []\n",
    "    for i, row in df.iterrows():\n",
    "        query, email, mobile, first_name, last_name = row\n",
    "        \n",
    "        entities = {\n",
    "            'Email': email,\n",
    "            'Mobile': mobile,\n",
    "            'FirstName': first_name,\n",
    "            'LastName': last_name,\n",
    "        }\n",
    "        \n",
    "        tokens = query.split()\n",
    "        \n",
    "        bio_tags = []\n",
    "        for token in tokens:\n",
    "            clean_token = token.strip(string.punctuation)\n",
    "            for entity, value in entities.items():\n",
    "                if clean_token in value:\n",
    "                    if value.startswith(clean_token):\n",
    "                        bio_tags.append('B-' + entity)\n",
    "                        break\n",
    "                    else:\n",
    "                        bio_tags.append('I-' + entity)\n",
    "                        break\n",
    "            else:\n",
    "                bio_tags.append('O')\n",
    "                \n",
    "        data.append(list(zip([token.strip(string.punctuation) for token in tokens], bio_tags)))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/shuffled_data.csv')\n",
    "bio_data = convert_to_bio_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ner_data.txt', 'w') as f:\n",
    "    for sentence in bio_data:\n",
    "        for word, tag in sentence:\n",
    "            f.write(f'{word} {tag}\\n')\n",
    "        f.write('\\n')  # Write a blank line to separate sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data and create a DataFrame\n",
    "flat_data = [(i, word, tag) for i, sentence in enumerate(bio_data, 1) for word, tag in sentence]\n",
    "df = pd.DataFrame(flat_data, columns=['SentenceID', 'Word', 'Tag'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('ner_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
